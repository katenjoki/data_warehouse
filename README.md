<h1>Data Engineering: Data Warehouse</h1>

This project is meant to use PostgreSQL, DBT, Airflow, and Spark in building a data warehouse. 

<h2>Getting started</h2>

The parquet data used for this project and more information on the data can be found [here](https://anson.ucdavis.edu/~clarkf/).

The goals of this project include:
* building and loading station data into a PostgreSQL database locally
* transforming the data using DBT
* orchestrating the workflow using Airflow

<h2>Prequisites</h2>
PostgreSQL, Python, DAG and Airflow should be installed in your local machine.

The rest of the necessary python packages required to run this project can be found in the requirements.txt file
